{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "consecutive-cabinet",
   "metadata": {},
   "source": [
    "# Python: A/B Testing with DoubleML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-indonesian",
   "metadata": {},
   "source": [
    "<img src=\"figures/ab_testing.png\" alt=\"An illustration of A/B testing.\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c96f88",
   "metadata": {},
   "source": [
    "In this notebook, we demontrate exemplarily how the [DoubleML](https://docs.doubleml.org/stable/index.html) package can be used to estimate the causal effect of seeing a new ad design on customers' purchases in a webshop. We base the estimation steps of our analysis according to the [DoubleML workflow](https://docs.doubleml.org/stable/workflow/workflow.html).\n",
    "\n",
    "\n",
    "## 0. Problem Formulation: A/B Testing\n",
    "\n",
    "\n",
    "### The A/B Testing Scenario\n",
    "\n",
    "Let's consider the following stylized scenario. The manager of a webshop performs an A/B test to estimate the effect a new ad design $A$ has on customers' purchases (in $100\\$$), $Y$, on average. This effect is called the **A**verage **T**reatment **E**ffect (**ATE**). The treatment is assigned randomly conditional on the visitors' characteristics, which we call $V$. Such characteristics could be collected from a customer's shoppers account, for example. These might include the number of previous purchases, time since the last purchase, length of stay on a page as well as whether a customer has a rewards card, among other characteristics. <br> \n",
    "\n",
    "In the following, we use a **D**irected **A**cyclical **G**raph (DAG) to illustrate our assumptions on the causal structure of the scenario. As not only the outcome, but also the treatment is dependent on the individual characteristics, there are arrows going from $V$ to both $A$ and $Y$. In our example, we also assume that the treatment $A$ is a direct cause of the customers' purchases $Y$.\n",
    "\n",
    "\n",
    "![Scenario illustration with a DAG](figures/DAG.svg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220997c6",
   "metadata": {},
   "source": [
    "Let's assume the conditional randomization has been conducted properly, such that a tidy data set has been collected. Now, a data scientist wants to evaluate whether the new ad design causally affected the sales, by using the [DoubleML](https://docs.doubleml.org/stable/index.html) package.\n",
    "\n",
    "### Why control for individual characteristics?\n",
    "\n",
    "Before we start the case study, let us briefly address the question why we need to include individual characteristics in our analysis at all. There are mainly two reasons why we want to control for observable characteristics. First, so-called confounders, i.e., variables that have a causal effect on both the treatment variable and the outcome variable, possibly create a bias in our estimate. In order to uncover the true causal effect of the treatment, it is necessary that our causal framework takes all confounding variables into account. Otherwise, the average causal effect of the treatment on the outcome is not identified. A second reason to include individual characteristics is efficiency. The more variation can be explained within our causal framework, the more precise will be the resulting estimate. In practical terms, greater efficiency leads to tighter confidence intervals and smaller standard errors and p-values. This might help to improve the power of A/B tests even if the treatment variable is unconditionally assigned to individuals.\n",
    "\n",
    "### Why use machine learning to analyze A/B tests?\n",
    "\n",
    "ML methods have turned out to be very flexible in terms of modeling complex relationships of explanatory variables and dependent variables and, thus, have exhibited a great predictive performance in many applications. In the double machine learning approach ([Chernozhukov et al. (2018)](https://arxiv.org/abs/1608.00060)), ML methods are used for modelling so-called nuisance functions. In terms of the A/B case study considered here, ML tools can be used to flexibly control for confounding variables. For example, a linear parametric specification as in a standard linear regression model might not be correct and, hence, not sufficient to account for the underlying confounding. Moreover, by using powerful ML techniques, the causal model will likely be able to explain a greater share of the total variation and, hence, lead to more precise estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec5b0cf",
   "metadata": {},
   "source": [
    "## 1. Data-Backend\n",
    "\n",
    "### The data set\n",
    "\n",
    "As an illustrative example we use a data set from the [ACIC 2019 Data Challenge](https://sites.google.com/view/acic2019datachallenge/data-challenge). In this challenge, a great number of data sets have been generated in a way that they mimic distributional relationships that are found in many economic real data applications. Although the data have not been generated explicitly to address an A/B testing case study, they are well-suited for demonstration purposes. We will focus on one of the many different data genereting processes (DGP) that we picked at random, in this particualar case a data set called `high42`. An advantage of using the synthetic [ACIC 2019 data](https://sites.google.com/view/acic2019datachallenge/data-challenge) is that we know the true average treatment effect which is 0.8 in our data set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaf4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import doubleml as dml\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LassoCV, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54723691",
   "metadata": {},
   "source": [
    "First we load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data set from url (internet connection required)\n",
    "url = 'https://raw.githubusercontent.com/DoubleML/doubleml-docs/master/doc/examples/data/high42.CSV'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10edc74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6760c009",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11525056-cdec-4916-9cb4-aa4268e99175",
   "metadata": {},
   "source": [
    "We see that the data set consists of 1000 observations (= website visitors) and 202 variables:\n",
    "\n",
    "* `Y`: A customer's purchases (in $100\\$$)\n",
    "* `A`: Binary treatment variable with a value 1 indicating that a customer has been exposed to the new ad design (and value 0 otherwise).\n",
    "* `V1`,..., `V200`: The remaining 200 columns $V$ represent individual characteristics of the customers (=confounders)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc6d08a",
   "metadata": {},
   "source": [
    "To start our analysis, we initialize the data backend from the previously loaded data set, i.e., we create a new instance of a [DoubleMLData](https://docs.doubleml.org/stable/guide/data_backend.html) object. During initialization, we specify the roles of the variables in the data set, i.e., in our example the outcome variable $Y$ via the parameter `y_col`, the treatment variable $A$ via `d_cols` and the confounding variables $V$ via `x_cols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdd10b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify explanatory variables for data-backend\n",
    "features_base = list(df.columns.values)[2:]\n",
    "\n",
    "# TODO: Initialize DoubleMLData (data-backend of DoubleML)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5800ca50-c293-4266-8dd7-00fadcea8d51",
   "metadata": {},
   "source": [
    "We can print the data-backend to see the variables, which we have assigned as outcome, treatment and controls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9bd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: print data backend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc4642b",
   "metadata": {},
   "source": [
    "## 2. Causal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714346b8-90dd-4f15-b880-d71f4f60b04e",
   "metadata": {},
   "source": [
    "The inference problem is to determine the causal effect of seeing the new ad design $A$ on customers' purchases $Y$ once we control for individual characteristics $V$. In our example, we are interested in the average treatment effect. Basically, there are two causal models available in [DoubleML](https://docs.doubleml.org/stable/) that can be used to estimate the ATE.\n",
    "\n",
    "The so-called **interactive regression model** (IRM) called by [DoubleMLIRM](https://docs.doubleml.org/stable/guide/models.html#interactive-regression-model-irm) is a flexible (nonparametric) model to estimate this causal quantity. The model does not impose functional form restrictions on the underlying regression relationships, for example, linearity or additivity as in a standard linear regression model. This means that the model hosts heterogeneous treatment effects, i.e., account for variation in the effect of the new ad design across customers. Moreover, it is possible to also estimate other causal parameters with the IRM, for example, the average treatment effect on the treated (= those customers who have been exposed to the new ad), which might be of interest too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e798e44-8fc8-4c93-9cfb-2d3ad7486dc0",
   "metadata": {},
   "source": [
    "### 2.1. Interactive regression model (IRM)\n",
    "\n",
    "We briefly introduce the [interactive regression model](https://docs.doubleml.org/stable/guide/models.html#interactive-regression-model-irm) where the main regression relationship of interest is provided by\n",
    "\n",
    "$$Y = g_0(A, V) + U_1, \\quad E(U_1 | V, A) = 0,$$\n",
    "\n",
    "where the treatment variable is binary, $A \\in \\lbrace 0,1 \\rbrace$. We consider estimation of the average treatment effect (ATE):\n",
    "\n",
    "$$\\theta_0 = \\mathbb{E}[g_0(1, V) - g_0(0,V)],$$\n",
    "\n",
    "when treatment effects are heterogeneous. In order to be able to use ML methods, the estimation framework generally requires a property called \"double robustness\" or \"Neyman orthogonality\". In the IRM, double robustness can be achieved by including the first-stage estimation\n",
    "\n",
    "$$A = m_0(V) + U_2, \\quad E(U_2| V) = 0,$$\n",
    "\n",
    "which amounts to estimation of the propensity score, i.e., the probability that a customer is exposed to the treatment provided her observed characteristics. Both predictions are then combined in [the doubly robust score for the average treatment effect](https://docs.doubleml.org/stable/guide/scores.html#interactive-regression-model-irm) which is given by\n",
    "\n",
    "$$\\psi(W; \\theta, \\eta) := g(1,V) - g(0,V) + \\frac{A (Y - g(1,V))}{m(V)} - \\frac{(1 - A)(Y - g(0,V))}{1 - m(V)} - \\theta.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2dc825",
   "metadata": {},
   "source": [
    "### 2.2. Naive Approach: Unconditional estimate of ATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da84d00",
   "metadata": {},
   "source": [
    "As a naive estimate, we could calculate the unconditional average treatment effect. In other words, we simply take the difference between $Y$ observed for the customers who have been exposed to the treatment $(A=1)$ and those who haven't been exposed $(A=0)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bcca63",
   "metadata": {},
   "source": [
    "Since the unconditional ATE does not account for the confounding variables, it will generally not correspond to the true ATE (only in the case of unconditionally random treatment assignment, the unconditional ATE will correspond to the true ATE). For example, if the unconditional ATE estimate is greater than the actual ATE, the manager would erroneously overinterpret the effect of the new ad design and probably make misleading decisions for the marketing budget in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate unconditional average treatment effect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5df754",
   "metadata": {},
   "source": [
    "## 3. ML Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0051af",
   "metadata": {},
   "source": [
    "In this step, we define the learners that will be used for estimation of the nuisance functions later.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee501e7",
   "metadata": {},
   "source": [
    "### 3.1. Benchmark using linear and logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba2b530",
   "metadata": {},
   "source": [
    "Let us first start with a benchmark model that is based on (unpenalized) linear and logistic regression. Hence, we estimate the functions $g_0(A,V)$ using a linear regression model and $m_0(V)$ by using an (unpenalized) logistic regression. In both cases, we include all available characteristics $V$. We will later compare the performance of this model to that using more advanced ML methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b85cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize Linear and Logistic Regression learners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f73377",
   "metadata": {},
   "source": [
    "### 3.2. Instantiate one or several ML learners of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cd5136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize one ML learner of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae15760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize a second ML learner of your choice\n",
    "#      (proceed as long as you like)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485cfe00",
   "metadata": {},
   "source": [
    "## 4. DML Specifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff1dd7",
   "metadata": {},
   "source": [
    "At this stage, we instantiate a causal model object of the class [DoubleMLIRM](https://docs.doubleml.org/stable/guide/models.html#interactive-regression-model-irm). Provide the learners via parameters `ml_g` and `ml_m`. You can either stick with the default setting or change the parameters. The API documentation is available [here](https://docs.doubleml.org/stable/api/generated/doubleml.DoubleMLIRM.html).\n",
    "\n",
    "**Hint**: Use [numpy.random.seed](https://numpy.org/doc/stable/reference/random/generated/numpy.random.seed.html) to set a random seed prior to your initialization. This makes the sample splits of the different models comparable. Also try to use the same DML specifications in all models to attain some comparability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc93139f",
   "metadata": {},
   "source": [
    "### 4.1. Linear and logistic benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f789572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize benchmark DoubleMLIRM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66a7a3f",
   "metadata": {},
   "source": [
    "### 4.2. ML Model of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b05c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialize a DoubleMLIRM model using the ML learners of your choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d358d8",
   "metadata": {},
   "source": [
    "### 4.3. - 4.X. ML Model of your choice\n",
    "\n",
    "Proceed with the models using the other ML learners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d7499b",
   "metadata": {},
   "source": [
    "### 5. Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77193485",
   "metadata": {},
   "source": [
    "### 5.1. Estimation for the Benchmark IRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f67cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit benchmark DoubleMLIRM model using the fit() method\n",
    "\n",
    "# HINT: set parameter 'store_predictions = True' for later model diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc97e056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Summarize your results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7013716",
   "metadata": {},
   "source": [
    "### 5.2. Estimation Diagnostics for the Benchmark IRM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cda529",
   "metadata": {},
   "source": [
    "#### 5.2.1. Assess the Predictive Performance in the benchmark IRM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e0ba66",
   "metadata": {},
   "source": [
    "To evaluate the different models we can compare how well the employed estimators fit the nuisance functions $g_0(\\cdot)$ and $m_0(\\cdot)$. Use the following helper function to compare the predictive performance of your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687b3f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_acc_irm(DoubleML, prop):\n",
    "    \"\"\"\n",
    "    A function to calculate prediction accuracy values for every repetition\n",
    "    of a Double Machine Learning model using IRM, DoubleMLIRM\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    DoubleML : doubleml.double_ml_irm.DoubleMLIRM\n",
    "        The IRM Double Machine Learning model\n",
    "    prop : bool\n",
    "        Indication if RMSE values have to be computed for main regression or\n",
    "        log loss values for propensity score\n",
    "    \"\"\"\n",
    "    \n",
    "    # export data and predictions of the DoubleML model\n",
    "    y = DoubleML._dml_data.y\n",
    "    d = DoubleML._dml_data.d\n",
    "    g0 = DoubleML.predictions.get('ml_g0')\n",
    "    g1 = DoubleML.predictions.get('ml_g1')    \n",
    "    m = DoubleML.predictions.get('ml_m')\n",
    "    \n",
    "    # dimensions of prediction array\n",
    "    h = g0.shape[0]\n",
    "    w = DoubleML.n_rep\n",
    "    \n",
    "    # check whether treatment is binary \n",
    "    if np.isin(d, [0,1]).all() == False:\n",
    "        raise ValueError(\"Treatment must be a binary variable.\")\n",
    "    \n",
    "    # prepare array to store prediction accuracy measure values\n",
    "    pred_acc_array = np.zeros((w,))\n",
    "    \n",
    "    # check whether to assess main regression or propensity score accuracy:   \n",
    "    if prop == False:\n",
    "        \n",
    "        # evaluate main regression accuracy\n",
    "        # export an array with correctly picked prediction values    \n",
    "        export_pred_array = np.zeros((h, w))            \n",
    "        for i in range(w):\n",
    "            for j in range(h):\n",
    "                if d[j] == 0:\n",
    "                    export_pred_array[j,i] = g0[j,i]\n",
    "                else:\n",
    "                    export_pred_array[j,i] = g1[j,i]\n",
    "    \n",
    "        # fill array that contains rmse of each repetition\n",
    "        for i in range(w):\n",
    "            pred_acc_array[i] = mean_squared_error(y, export_pred_array[:,i], squared=False)    \n",
    "    else:\n",
    "        \n",
    "        # evaluate propensity score accuracy\n",
    "        # fill array that contains log loss of each repetition\n",
    "        for i in range(w):\n",
    "            pred_acc_array[i] = log_loss(d, m[:,i], eps=0.025)\n",
    "    \n",
    "    return pred_acc_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3d1b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate the predictive performance for `ml_g` and `ml_m` using the\n",
    "#       helper function `pred_acc_irm()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab17ca98",
   "metadata": {},
   "source": [
    "#### Optional: 5.2.2. Evaluation of Propensity Score Estimates in the Benchmark IRM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adef2901",
   "metadata": {},
   "source": [
    "The propensity score $m_0(A,V)$ plays an important role in the [score of the IRM model](https://docs.doubleml.org/stable/guide/scores.html#interactive-regression-model-irm). Try to summarize the estimates for $m_0(A,V)$ using some descriptive statistics or visualization. You can use the following helper function for visualizing the propensity score estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d407022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_propscore_plot(DoubleML):\n",
    "    \"\"\"\n",
    "    A function to create histograms as sublots for every repetition's propensity score density \n",
    "    of a Double Machine Learning model\n",
    "    \n",
    "    ...\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    DoubleML : doubleml\n",
    "        The Double Machine Learning model\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #export nuisance part from the DoubleML model\n",
    "    m = DoubleML.predictions.get('ml_m')\n",
    "    \n",
    "    # dimensions of nuisance array\n",
    "    h = m.shape[0]\n",
    "    rep = DoubleML.n_rep\n",
    "    i = 0\n",
    "    \n",
    "    # create histograms as subplots covering the propensity score densities of all repetitions\n",
    "    if rep > 1:\n",
    "        fig, ax = plt.subplots(1, rep, figsize=[20,4.8])\n",
    "    \n",
    "        for i in range(rep):\n",
    "            ax[i].hist(np.reshape(m[:,i], h), range=[0,1], bins=25, density=False)\n",
    "            ax[i].set_title('repetition ' + str(i+1))\n",
    "            ax[i].set_xlabel(\"prop_score\")\n",
    "            ax[i].set_ylabel(\"count\")\n",
    "    \n",
    "    else:\n",
    "        fig, ax = plt.subplots(figsize=[20,4.8])\n",
    "        ax.hist(np.reshape(m[:,i], h), range=[0,1], bins=25, density=False)\n",
    "        ax.hist(np.reshape(m[:,i], h), range=[0,1], bins=25, density=False)\n",
    "        ax.set_title('repetition ' + str(i+1))\n",
    "        ax.set_xlabel(\"prop_score\")\n",
    "        ax.set_ylabel(\"count\")\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7a9c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TODO): Summarize the propensity score estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27a820d",
   "metadata": {},
   "source": [
    "### 5.3. Estimation for ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b71fc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit the ML DoubleMLIRM model using the fit() method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445bdf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Summarize your results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7b702e",
   "metadata": {},
   "source": [
    "### 5.3. Estimation Diagnostics for the IRM using ML Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f4bde9",
   "metadata": {},
   "source": [
    "#### 5.3.1. Assess the Predictive Performance in the IRM using ML methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39351644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluate the predictive performance for `ml_g` and `ml_m` using the\n",
    "#       helper function `pred_acc_irm()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7859d79",
   "metadata": {},
   "source": [
    "#### Optional: 5.3.2. Evaluation of Propensity Score Estimates in the Benchmark IRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8d06d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TODO): Summarize the propensity score estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac52d35",
   "metadata": {},
   "source": [
    "### 5.4. - 5.X. ML Model of your choice\n",
    "\n",
    "Proceed with the models using the other ML learners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4096a9e",
   "metadata": {},
   "source": [
    "### 5.X+1 Summarize your Results on the Quality of Estimation \n",
    "\n",
    "Provide a brief summary of your estimation results, for example by creating a table or figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a1c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Summarize the results on the nuisance estimation in a table or figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13755e30",
   "metadata": {},
   "source": [
    "## 6. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204cfd97",
   "metadata": {},
   "source": [
    "Summarize your results on the **coefficient estimate** for $\\theta_0$ as well as the **standard errors** and / or **confidence intervals**, respectively. You can create a table or a figure illustrating your findings.\n",
    "\n",
    "Try to answer the following questions: \n",
    "\n",
    "* Can you reject the $H_0$ that the new add ($A$) has no effect on sales ($Y$) at common significance levels?\n",
    "* How close is your estimate to the true value of $\\theta_0=0.8$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9748ce11",
   "metadata": {},
   "source": [
    "### 6.1. Inference for the benchmark IRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462aa7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: After calling fit(), access the coefficient parameter,\n",
    "##      the standard error and confidence interval accessing the fiels\n",
    "##      `coef` and `summary`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0effcb",
   "metadata": {},
   "source": [
    "### 6.2. Inference for the IRM using ML methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5b185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: After calling fit(), access the coefficient parameter,\n",
    "##      the standard error and confidence interval accessing the fiels\n",
    "##      `coef` and `summary`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e86ba0",
   "metadata": {},
   "source": [
    "### 6.3. - 6.X. ML Model of your choice\n",
    "\n",
    "Proceed with the models using the other ML learners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa8d603-0df5-48c6-ad62-ac5ffe3e8ada",
   "metadata": {},
   "source": [
    "______\n",
    "\n",
    "**Notes and Acknowledgement**\n",
    "\n",
    "We would like to thank the organizers of the [ACIC 2019 Data Challenge](https://sites.google.com/view/acic2019datachallenge/data-challenge) for setting up this data challenge and making the numerous synthetic data examples publicly available.  Although the data examples in the [ACIC 2019 Data Challenge](https://sites.google.com/view/acic2019datachallenge/data-challenge) do not explicitly adress A/B testing, we put the data example here in this context to give a tractable example on the use of causal machine learning in practice. The parameters for the random forests and extreme gradient boosting learners have been tuned externally. The corresponding tuning notebook will be uploaded in the [examples gallery](https://docs.doubleml.org/dev/examples/index.html) in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "egyptian-platform",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "Chernozhukov, V., Chetverikov, D., Demirer, M., Duflo, E., Hansen, C., Newey, W. and Robins, J. (2018), Double/debiased machine learning for treatment and structural parameters. The Econometrics Journal, 21: C1-C68. doi:10.1111/ectj.12097."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
